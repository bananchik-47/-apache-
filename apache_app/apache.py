import sqlite3
import configparser
import os
import re
import sys
from datetime import datetime
import argparse
from tqdm import tqdm
import time

class SimpleLogTool:
    def __init__(self):
        self.config = configparser.ConfigParser()
        self.load_settings()
        db_file_path = self.config['Ğ‘Ğ°Ğ·Ğ°Ğ”Ğ°Ğ½Ğ½Ñ‹Ñ…']['ĞŸĞ£Ğ¢Ğ¬'].replace('sqlite:///', '')
        self.database_file = db_file_path
        self.setup_database()

    def load_settings(self):
        self.config.read('config.ini')
        if not self.config.sections():
            self.config['Ğ‘Ğ°Ğ·Ğ°Ğ”Ğ°Ğ½Ğ½Ñ‹Ñ…'] = {'ĞŸĞ£Ğ¢Ğ¬': 'sqlite:///logs.db'}
            self.config['Ğ›Ğ¾Ğ³Ğ¸'] = {'ĞŸĞ°Ğ¿ĞºĞ°': 'logs', 'Ğ˜Ğ¼ÑĞ¤Ğ°Ğ¹Ğ»Ğ°': 'access.log'}
            with open('config.ini', 'w') as config_file:
                self.config.write(config_file)

    def setup_database(self):
        folder = os.path.dirname(self.database_file)
        if folder:
            os.makedirs(folder, exist_ok=True)

        conn = sqlite3.connect(self.database_file)
        cursor = conn.cursor()
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS log_entries (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ip TEXT,
                date TEXT,
                method TEXT,
                url TEXT,
                status INTEGER,
                size INTEGER,
                user_agent TEXT
            )
        ''')
        conn.commit()
        conn.close()

    def import_logs(self):
        log_file_path = os.path.join(
            self.config['Ğ›Ğ¾Ğ³Ğ¸']['ĞŸĞ°Ğ¿ĞºĞ°'],
            self.config['Ğ›Ğ¾Ğ³Ğ¸']['Ğ˜Ğ¼ÑĞ¤Ğ°Ğ¹Ğ»Ğ°']
        )

        if not os.path.exists(log_file_path):
            print(f"â›” Ğ¤Ğ°Ğ¹Ğ» Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½: {log_file_path}")
            print("ĞŸĞ¾ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸ config.ini")
            return False

        with open(log_file_path, 'r', encoding='utf-8') as f:
            total_lines = sum(1 for _ in f)

        conn = sqlite3.connect(self.database_file)
        cursor = conn.cursor()
        inserted = 0

        print(f"\nğŸ“‚ ĞÑ‚ĞºÑ€Ñ‹Ğ²Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ» Ğ»Ğ¾Ğ³Ğ¾Ğ²: {log_file_path}")
        with tqdm(total=total_lines, desc="ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°", unit="ÑÑ‚Ñ€Ğ¾Ğº") as progress:
            with open(log_file_path, 'r', encoding='utf-8') as log_file:
                for line in log_file:
                    line = line.strip()
                    try:
                        parsed = self.parse_line(line)
                        if parsed:
                            cursor.execute('''
                                INSERT INTO log_entries 
                                (ip, date, method, url, status, size, user_agent)
                                VALUES (?, ?, ?, ?, ?, ?, ?)
                            ''', parsed)
                            inserted += 1
                    except Exception as error:
                        print(f"\nâš  ĞÑˆĞ¸Ğ±ĞºĞ°: {error}", file=sys.stderr)
                    finally:
                        progress.update(1)
                        time.sleep(0.001)

        conn.commit()
        conn.close()

        print(f"\nâœ… Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¾. ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ¾: {inserted}/{total_lines}")
        print(f"Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¾ Ğ² Ğ±Ğ°Ğ·Ñƒ: {self.database_file}")
        return True

    def parse_line(self, log_line):
        regex = r'^(\S+) \S+ \S+ \[(.*?)\] "(.*?)" (\d+) (\d+) "(.*?)" "(.*?)"'
        match = re.match(regex, log_line)

        if not match:
            return None

        ip, date_str, request, status, size, referrer, user_agent = match.groups()

        try:
            method, url, _ = request.split(' ', 2)
        except:
            return None

        try:
            date_parsed = datetime.strptime(date_str, '%d/%b/%Y:%H:%M:%S %z').isoformat()
        except:
            date_parsed = date_str

        if user_agent == '-':
            user_agent = None

        return (
            ip,
            date_parsed,
            method,
            url,
            int(status),
            int(size),
            user_agent
        )

    def show_logs(self, filters):
        conn = sqlite3.connect(self.database_file)
        cursor = conn.cursor()

        where_conditions = []
        parameters = []

        if filters.get('ip'):
            where_conditions.append("ip = ?")
            parameters.append(filters['ip'])
        if filters.get('keyword'):
            where_conditions.append("url LIKE ?")
            parameters.append(f"%{filters['keyword']}%")
        if filters.get('date_from'):
            where_conditions.append("date >= ?")
            parameters.append(filters['date_from'])
        if filters.get('date_to'):
            where_conditions.append("date <= ?")
            parameters.append(filters['date_to'])

        where_sql = "WHERE " + " AND ".join(where_conditions) if where_conditions else ""
        limit_sql = f"LIMIT {filters.get('limit', 100)}"

        query = f"SELECT * FROM log_entries {where_sql} ORDER BY date DESC {limit_sql}"

        cursor.execute(query, parameters)
        logs = cursor.fetchall()

        if not logs:
            print("\nğŸ” ĞĞ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾.")
            return

        print("\nğŸ“‹ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸:")
        print("-" * 120)
        print(f"| {'IP':<15} | {'Ğ”Ğ°Ñ‚Ğ°':<20} | {'ĞœĞµÑ‚Ğ¾Ğ´':<6} | {'URL':<40} | {'ĞšĞ¾Ğ´':<6} | {'Ğ Ğ°Ğ·Ğ¼ĞµÑ€':<6} |")
        print("-" * 120)

        for log in logs:
            print(f"| {log[1]:<15} | {log[2][:19]:<20} | {log[3]:<6} | {log[4][:40]:<40} | {log[5]:<6} | {log[6]:<6} |")

        print("-" * 120)
        print(f"ğŸ“Š Ğ’ÑĞµĞ³Ğ¾ ÑÑ‚Ñ€Ğ¾Ğº: {len(logs)}")
        conn.close()

def print_help():
    print("\nğŸ“Œ ĞŸÑ€Ğ¾ÑÑ‚ĞµĞ½ÑŒĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ»Ğ¾Ğ³Ğ¾Ğ² (Apache)")
    print("ĞšĞ°Ğº Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ:")
    print("  python apache.py parse       - Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ»Ğ¾Ğ³Ğ¸ Ğ¸Ğ· access.log Ğ² Ğ±Ğ°Ğ·Ñƒ")
    print("  python apache.py show        - ĞŸĞ¾ÑĞ¼Ğ¾Ñ‚Ñ€ĞµÑ‚ÑŒ Ğ»Ğ¾Ğ³Ğ¸ (Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 100 ÑˆÑ‚ÑƒĞº)")
    print("\nĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ:")
    print("  --ip IP_ADDRESS           - Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ IP")
    print("  --keyword Ğ¡Ğ›ĞĞ’Ğ           - Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ URL")
    print("  --date-from YYYY-MM-DD    - ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ°")
    print("  --date-to YYYY-MM-DD      - ĞšĞ¾Ğ½ĞµÑ† Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ°")
    print("  --limit Ğ¡ĞšĞĞ›Ğ¬ĞšĞ           - Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑÑ‚Ñ€Ğ¾Ğº (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 100)")
    print("\nĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹:")
    print("  python apache.py show --ip 127.0.0.1 --limit 20")
    print("  python apache.py show --keyword admin --date-from 2024-01-01")

def main():
    if len(sys.argv) == 1:
        print_help()
        return

    parser = argparse.ArgumentParser(description='ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ»Ğ¾Ğ³Ğ¾Ğ²', usage='python apache.py [parse|show] [Ğ¾Ğ¿Ñ†Ğ¸Ğ¸]')
    subparsers = parser.add_subparsers(dest='command', required=True)

    subparsers.add_parser('parse', help='Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ»Ğ¾Ğ³Ğ¸ Ğ² Ğ±Ğ°Ğ·Ñƒ')
    show_parser = subparsers.add_parser('show', help='ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ÑŒ Ğ»Ğ¾Ğ³Ğ¸')
    show_parser.add_argument('--ip', help='IP Ğ°Ğ´Ñ€ĞµÑ')
    show_parser.add_argument('--keyword', help='ĞšĞ»ÑÑ‡ĞµĞ²Ğ¾Ğµ ÑĞ»Ğ¾Ğ²Ğ¾ Ğ² URL')
    show_parser.add_argument('--date-from', help='Ğ¡ ĞºĞ°ĞºĞ¾Ğ¹ Ğ´Ğ°Ñ‚Ñ‹')
    show_parser.add_argument('--date-to', help='ĞŸĞ¾ ĞºĞ°ĞºÑƒÑ Ğ´Ğ°Ñ‚Ñƒ')
    show_parser.add_argument('--limit', type=int, default=100, help='Ğ¡ĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑÑ‚Ñ€Ğ¾Ğº')

    args = parser.parse_args()
    analyzer = SimpleLogTool()

    if args.command == 'parse':
        analyzer.import_logs()
    elif args.command == 'show':
        analyzer.show_logs({
            'ip': args.ip,
            'keyword': args.keyword,
            'date_from': args.date_from,
            'date_to': args.date_to,
            'limit': args.limit
        })

if __name__ == '__main__':
    print("ğŸ› ï¸ ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ»Ğ¾Ğ³Ğ¾Ğ²")
    main()
